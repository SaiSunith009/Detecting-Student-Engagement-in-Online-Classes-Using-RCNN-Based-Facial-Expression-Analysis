# Detecting-Student-Engagement-in-Online-Classes-Using-RCNN-Based-Facial-Expression-Analysis

My project, “Detecting Student Engagement in Online Classes Using RCNN-Based Facial Expression Analysis,” addresses one of the biggest challenges in virtual education: understanding how engaged students are during online lessons. In traditional classrooms, teachers can easily pick up on students’ emotions and attention through body language and facial expressions. However, this feedback is often missing in online environments, making it tough for instructors to know if students are focused, confused, or losing interest.

To solve this, I developed an intelligent system that uses deep learning—specifically, Recurrent Convolutional Neural Networks (RCNNs)—to analyze students’ facial expressions in real time via their webcams. The system processes video frames, extracts facial features, and tracks changes in expressions over time. This allows it to classify students’ engagement levels into categories such as Engaged, Not Interested, Confused, or Disliking the Topic.

The results are delivered instantly to teachers through a user-friendly interface, helping them identify students who might need extra support or encouragement. All engagement data is securely stored for later analysis, enabling educators to track trends and adapt their teaching methods.

This project not only automates the process of monitoring engagement but also helps create a more responsive and supportive online learning experience. With high accuracy and real-time feedback, it brings the human touch back to digital classrooms, ensuring every student gets the attention they need to succeed.
